{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chrysalis SQLite Diff Visual\n",
    "\n",
    "Compares two Diaphora/BinDiff-style SQLite databases from `databases/` and classifies functions as:\n",
    "\n",
    "- `same`\n",
    "- `patched`\n",
    "- `added_in_patched`\n",
    "- `removed_from_patched`\n",
    "\n",
    "CSV outputs are written to `notebooks/tables/db_diff_reports/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import hashlib\n",
    "import sqlite3\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    HAVE_PLOTLY = True\n",
    "except Exception:\n",
    "    HAVE_PLOTLY = False\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "if not (ROOT / \"databases\").exists() and (ROOT.parent / \"databases\").exists():\n",
    "    ROOT = ROOT.parent\n",
    "DB_DIR = ROOT / \"databases\"\n",
    "REPORT_DIR = ROOT / \"notebooks\" / \"tables\" / \"db_diff_reports\"\n",
    "REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dbs = sorted([p for p in DB_DIR.glob(\"*.sqlite\")])\n",
    "if len(dbs) < 2:\n",
    "    raise RuntimeError(f\"Expected at least 2 sqlite DBs in {DB_DIR}, found {len(dbs)}\")\n",
    "\n",
    "def pick_pair(paths: List[Path]) -> Tuple[Path, Path]:\n",
    "    legit = None\n",
    "    patched = None\n",
    "    for p in paths:\n",
    "        n = p.name.lower()\n",
    "        if \"bluetoothservice\" in n:\n",
    "            legit = p\n",
    "        if \"patched\" in n or \"main_module\" in n:\n",
    "            patched = p\n",
    "    if legit and patched:\n",
    "        return legit, patched\n",
    "    return paths[0], paths[1]\n",
    "\n",
    "DB_LEGIT, DB_PATCHED = pick_pair(dbs)\n",
    "print(\"LEGIT DB:\", DB_LEGIT)\n",
    "print(\"PATCHED DB:\", DB_PATCHED)\n",
    "print(\"REPORT DIR:\", REPORT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FnMeta:\n",
    "    func_id: int\n",
    "    name: str\n",
    "    address: int\n",
    "    size: int\n",
    "    nodes: int\n",
    "    edges: int\n",
    "\n",
    "\n",
    "def load_function_meta(conn: sqlite3.Connection) -> Dict[int, FnMeta]:\n",
    "    q = \"\"\"\n",
    "    SELECT id, COALESCE(name, ''), COALESCE(address, 0), COALESCE(size, 0), COALESCE(nodes, 0), COALESCE(edges, 0)\n",
    "    FROM functions\n",
    "    \"\"\"\n",
    "    out: Dict[int, FnMeta] = {}\n",
    "    for fid, name, addr, size, nodes, edges in conn.execute(q):\n",
    "        out[int(fid)] = FnMeta(\n",
    "            func_id=int(fid),\n",
    "            name=str(name),\n",
    "            address=int(addr),\n",
    "            size=int(size),\n",
    "            nodes=int(nodes),\n",
    "            edges=int(edges),\n",
    "        )\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_digests(db_path: Path) -> pd.DataFrame:\n",
    "    conn = sqlite3.connect(str(db_path))\n",
    "    try:\n",
    "        meta = load_function_meta(conn)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT func_id, address, COALESCE(mnemonic, ''), COALESCE(disasm, '')\n",
    "            FROM instructions\n",
    "            ORDER BY func_id, address\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        rows = []\n",
    "        last_fid = None\n",
    "        m_hasher = hashlib.sha1()\n",
    "        d_hasher = hashlib.sha1()\n",
    "        inst_count = 0\n",
    "        preview = []\n",
    "\n",
    "        def flush(fid):\n",
    "            nonlocal rows, m_hasher, d_hasher, inst_count, preview\n",
    "            if fid is None or fid not in meta:\n",
    "                return\n",
    "            m = meta[fid]\n",
    "            rows.append({\n",
    "                \"address\": m.address,\n",
    "                \"name\": m.name,\n",
    "                \"size\": m.size,\n",
    "                \"nodes\": m.nodes,\n",
    "                \"edges\": m.edges,\n",
    "                \"inst_count\": inst_count,\n",
    "                \"mnemonic_sha1\": m_hasher.hexdigest(),\n",
    "                \"disasm_sha1\": d_hasher.hexdigest(),\n",
    "                \"mnemonic_preview\": \" \".join(preview[:80]),\n",
    "            })\n",
    "\n",
    "        for fid, _addr, mnemonic, disasm in cur:\n",
    "            fid = int(fid)\n",
    "            if last_fid is None:\n",
    "                last_fid = fid\n",
    "            if fid != last_fid:\n",
    "                flush(last_fid)\n",
    "                last_fid = fid\n",
    "                m_hasher = hashlib.sha1()\n",
    "                d_hasher = hashlib.sha1()\n",
    "                inst_count = 0\n",
    "                preview = []\n",
    "\n",
    "            m_tok = str(mnemonic)\n",
    "            d_tok = str(disasm)\n",
    "            m_hasher.update(m_tok.encode(\"utf-8\", errors=\"ignore\"))\n",
    "            m_hasher.update(b\"\\x00\")\n",
    "            d_hasher.update(d_tok.encode(\"utf-8\", errors=\"ignore\"))\n",
    "            d_hasher.update(b\"\\x00\")\n",
    "            inst_count += 1\n",
    "            if len(preview) < 80:\n",
    "                preview.append(m_tok)\n",
    "\n",
    "        flush(last_fid)\n",
    "        df = pd.DataFrame(rows)\n",
    "        if not df.empty:\n",
    "            df[\"address_hex\"] = df[\"address\"].map(lambda x: f\"0x{x:08X}\")\n",
    "            df = df.sort_values([\"address\", \"name\"]).reset_index(drop=True)\n",
    "        return df\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "df_legit = build_digests(DB_LEGIT)\n",
    "df_patched = build_digests(DB_PATCHED)\n",
    "print(\"Functions (legit):\", len(df_legit))\n",
    "print(\"Functions (patched):\", len(df_patched))\n",
    "if df_legit.empty or df_patched.empty:\n",
    "    raise RuntimeError(\"Failed to compute function digests from one or both DBs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_cols = [\n",
    "    \"address\", \"name\", \"size\", \"nodes\", \"edges\", \"inst_count\", \"mnemonic_sha1\", \"disasm_sha1\", \"mnemonic_preview\"\n",
    "]\n",
    "L = df_legit[cmp_cols].copy()\n",
    "P = df_patched[cmp_cols].copy()\n",
    "merged = L.merge(P, on=\"address\", how=\"outer\", suffixes=(\"_legit\", \"_patched\"), indicator=True)\n",
    "\n",
    "def classify(row):\n",
    "    if row[\"_merge\"] == \"left_only\":\n",
    "        return \"removed_from_patched\"\n",
    "    if row[\"_merge\"] == \"right_only\":\n",
    "        return \"added_in_patched\"\n",
    "    if row[\"mnemonic_sha1_legit\"] == row[\"mnemonic_sha1_patched\"] and row[\"disasm_sha1_legit\"] == row[\"disasm_sha1_patched\"]:\n",
    "        return \"same\"\n",
    "    return \"patched\"\n",
    "\n",
    "merged[\"classification\"] = merged.apply(classify, axis=1)\n",
    "patched_df = merged[merged[\"classification\"] == \"patched\"].copy()\n",
    "if not patched_df.empty:\n",
    "    patched_df[\"inst_delta\"] = (patched_df[\"inst_count_patched\"].fillna(0) - patched_df[\"inst_count_legit\"].fillna(0)).abs()\n",
    "    patched_df[\"size_delta\"] = (patched_df[\"size_patched\"].fillna(0) - patched_df[\"size_legit\"].fillna(0)).abs()\n",
    "\n",
    "summary = merged.groupby(\"classification\", dropna=False).size().reset_index(name=\"count\").sort_values(\"count\", ascending=False)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(REPORT_DIR / \"summary.csv\", index=False)\n",
    "merged.to_csv(REPORT_DIR / \"all_functions_classified.csv\", index=False)\n",
    "merged[merged[\"classification\"] == \"same\"].to_csv(REPORT_DIR / \"same_functions.csv\", index=False)\n",
    "merged[merged[\"classification\"] == \"added_in_patched\"].to_csv(REPORT_DIR / \"added_in_patched.csv\", index=False)\n",
    "merged[merged[\"classification\"] == \"removed_from_patched\"].to_csv(REPORT_DIR / \"removed_from_patched.csv\", index=False)\n",
    "if not patched_df.empty:\n",
    "    patched_df.sort_values([\"inst_delta\", \"size_delta\"], ascending=False).to_csv(REPORT_DIR / \"patched_functions.csv\", index=False)\n",
    "    patched_df[[\"address\", \"name_legit\", \"name_patched\", \"mnemonic_preview_legit\", \"mnemonic_preview_patched\"]].head(200).to_csv(REPORT_DIR / \"patched_preview_mnemonics.csv\", index=False)\n",
    "\n",
    "print(\"Wrote reports to\", REPORT_DIR)\n",
    "for p in sorted(REPORT_DIR.glob(\"*.csv\")):\n",
    "    print(\" -\", p.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAVE_PLOTLY:\n",
    "    fig = px.bar(summary, x=\"classification\", y=\"count\", title=\"Function Classification Summary\")\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"Plotly not installed; skipping chart\")\n",
    "\n",
    "if not patched_df.empty:\n",
    "    cols = [\n",
    "        \"address\", \"name_legit\", \"name_patched\",\n",
    "        \"inst_count_legit\", \"inst_count_patched\",\n",
    "        \"size_legit\", \"size_patched\",\n",
    "        \"inst_delta\", \"size_delta\"\n",
    "    ]\n",
    "    display(patched_df.sort_values([\"inst_delta\", \"size_delta\"], ascending=False)[cols].head(50))\n",
    "else:\n",
    "    print(\"No patched functions detected\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
